// Copyright 2021 ETH Zurich and University of Bologna.
// Solderpad Hardware License, Version 0.51, see LICENSE for details.
// SPDX-License-Identifier: SHL-0.51
//
// Author: Matheus Cavalcante <matheusd@iis.ee.ethz.ch>
//         Basile Bougenot <bbougenot@student.ethz.ch>

#include "vector_macros.h"

void TEST_CASE1() {
  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  VLOAD_8(v3, 0xf0, 0x03, 0xf0, 0xf0, 0x03, 0xf0, 0xf0, 0x03, 0xf0, 0xf0, 0x03,
          0xf0);
  asm volatile("vxor.vv v1, v2, v3");
  VCMP_U8(1, v1, 0x0f, 0x02, 0x00, 0x0f, 0x02, 0x00, 0x0f, 0x02, 0x00, 0x0f,
          0x02, 0x00);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  VLOAD_16(v3, 0xff00, 0x0003, 0xf0f0, 0xff00, 0x0003, 0xf0f0, 0xff00, 0x0003,
           0xf0f0, 0xff00, 0x0003, 0xf0f0);
  asm volatile("vxor.vv v1, v2, v3");
  VCMP_U16(2, v1, 0x00ff, 0x0002, 0x0000, 0x00ff, 0x0002, 0x0000, 0x00ff,
           0x0002, 0x0000, 0x00ff, 0x0002, 0x0000);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  VLOAD_32(v3, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003,
           0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000,
           0x00000003, 0xf0f0f0f0);
  asm volatile("vxor.vv v1, v2, v3");
  VCMP_U32(3, v1, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff, 0x00000002,
           0x00000000, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff,
           0x00000002, 0x00000000);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   VLOAD_64(v3, 0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0);
//   asm volatile("vxor.vv v1, v2, v3");
//   VCMP_U64(4, v1, 0x00000000ffffffff, 0x0000000000000002, 0x0000000000000000,
//            0x00000000ffffffff, 0x0000000000000002, 0x0000000000000000,
//            0x00000000ffffffff, 0x0000000000000002, 0x0000000000000000,
//            0x00000000ffffffff, 0x0000000000000002, 0x0000000000000000);
}

void TEST_CASE2() {
  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  VLOAD_8(v3, 0xf0, 0x03, 0xf0, 0xf0, 0x03, 0xf0, 0xf0, 0x03, 0xf0, 0xf0, 0x03,
          0xf0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_8(v1, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef,
          0xef);
  asm volatile("vxor.vv v1, v2, v3, v0.t");
  VCMP_U8(5, v1, 0x0f, 0xef, 0x00, 0x0f, 0xef, 0x00, 0x0f, 0xef, 0x00, 0x0f,
          0xef, 0x00);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  VLOAD_16(v3, 0xff00, 0x0003, 0xf0f0, 0xff00, 0x0003, 0xf0f0, 0xff00, 0x0003,
           0xf0f0, 0xff00, 0x0003, 0xf0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_16(v1, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef,
           0xbeef, 0xbeef, 0xbeef, 0xbeef);
  asm volatile("vxor.vv v1, v2, v3, v0.t");
  VCMP_U16(6, v1, 0x00ff, 0xbeef, 0x0000, 0x00ff, 0xbeef, 0x0000, 0x00ff,
           0xbeef, 0x0000, 0x00ff, 0xbeef, 0x0000);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  VLOAD_32(v3, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003,
           0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000,
           0x00000003, 0xf0f0f0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_32(v1, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef);
  asm volatile("vxor.vv v1, v2, v3, v0.t");
  VCMP_U32(7, v1, 0x0000ffff, 0xdeadbeef, 0x00000000, 0x0000ffff, 0xdeadbeef,
           0x00000000, 0x0000ffff, 0xdeadbeef, 0x00000000, 0x0000ffff,
           0xdeadbeef, 0x00000000);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   VLOAD_64(v3, 0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0,
//            0xffffffff00000000, 0x0000000000000003, 0xf0f0f0f0f0f0f0f0);
//   VLOAD_8(v0, 0x6D, 0x0B);
//   VLOAD_64(v1, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef);
//   asm volatile("vxor.vv v1, v2, v3, v0.t");
//   VCMP_U64(8, v1, 0x00000000ffffffff, 0xdeadbeefdeadbeef, 0x0000000000000000,
//            0x00000000ffffffff, 0xdeadbeefdeadbeef, 0x0000000000000000,
//            0x00000000ffffffff, 0xdeadbeefdeadbeef, 0x0000000000000000,
//            0x00000000ffffffff, 0xdeadbeefdeadbeef, 0x0000000000000000);
}

void TEST_CASE3() {
  const uint64_t scalar = 0x0ff00ff00ff00ff0;

  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  asm volatile("vxor.vx v1, v2, %[A]" ::[A] "r"(scalar));
  VCMP_U8(9, v1, 0x0f, 0xf1, 0x00, 0x0f, 0xf1, 0x00, 0x0f, 0xf1, 0x00, 0x0f,
          0xf1, 0x00);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  asm volatile("vxor.vx v1, v2, %[A]" ::[A] "r"(scalar));
  VCMP_U16(10, v1, 0xf00f, 0x0ff1, 0xff00, 0xf00f, 0x0ff1, 0xff00, 0xf00f,
           0x0ff1, 0xff00, 0xf00f, 0x0ff1, 0xff00);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  asm volatile("vxor.vx v1, v2, %[A]" ::[A] "r"(scalar));
  VCMP_U32(11, v1, 0xf00ff00f, 0x0ff00ff1, 0xff00ff00, 0xf00ff00f, 0x0ff00ff1,
           0xff00ff00, 0xf00ff00f, 0x0ff00ff1, 0xff00ff00, 0xf00ff00f,
           0x0ff00ff1, 0xff00ff00);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   asm volatile("vxor.vx v1, v2, %[A]" ::[A] "r"(scalar));
//   VCMP_U64(12, v1, 0xf00ff00ff00ff00f, 0x0ff00ff00ff00ff1, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0x0ff00ff00ff00ff1, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0x0ff00ff00ff00ff1, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0x0ff00ff00ff00ff1, 0xff00ff00ff00ff00);
}

void TEST_CASE4() {
  const uint64_t scalar = 0x0ff00ff00ff00ff0;

  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_8(v1, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef,
          0xef);
  asm volatile("vxor.vx v1, v2, %[A], v0.t" ::[A] "r"(scalar));
  VCMP_U8(13, v1, 0x0f, 0xef, 0x00, 0x0f, 0xef, 0x00, 0x0f, 0xef, 0x00, 0x0f,
          0xef, 0x00);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_16(v1, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef,
           0xbeef, 0xbeef, 0xbeef, 0xbeef);
  asm volatile("vxor.vx v1, v2, %[A], v0.t" ::[A] "r"(scalar));
  VCMP_U16(14, v1, 0xf00f, 0xbeef, 0xff00, 0xf00f, 0xbeef, 0xff00, 0xf00f,
           0xbeef, 0xff00, 0xf00f, 0xbeef, 0xff00);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_32(v1, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef);
  asm volatile("vxor.vx v1, v2, %[A], v0.t" ::[A] "r"(scalar));
  VCMP_U32(15, v1, 0xf00ff00f, 0xdeadbeef, 0xff00ff00, 0xf00ff00f, 0xdeadbeef,
           0xff00ff00, 0xf00ff00f, 0xdeadbeef, 0xff00ff00, 0xf00ff00f,
           0xdeadbeef, 0xff00ff00);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   VLOAD_8(v0, 0x6D, 0x0B);
//   VLOAD_64(v1, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef);
//   asm volatile("vxor.vx v1, v2, %[A], v0.t" ::[A] "r"(scalar));
//   VCMP_U64(16, v1, 0xf00ff00ff00ff00f, 0xdeadbeefdeadbeef, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0xdeadbeefdeadbeef, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0xdeadbeefdeadbeef, 0xff00ff00ff00ff00,
//            0xf00ff00ff00ff00f, 0xdeadbeefdeadbeef, 0xff00ff00ff00ff00);
}

void TEST_CASE5() {
  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  asm volatile("vxor.vi v1, v2, 15");
  VCMP_U8(17, v1, 0xf0, 0x0e, 0xff, 0xf0, 0x0e, 0xff, 0xf0, 0x0e, 0xff, 0xf0,
          0x0e, 0xff);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  asm volatile("vxor.vi v1, v2, 15");
  VCMP_U16(18, v1, 0xfff0, 0x000e, 0xf0ff, 0xfff0, 0x000e, 0xf0ff, 0xfff0,
           0x000e, 0xf0ff, 0xfff0, 0x000e, 0xf0ff);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  asm volatile("vxor.vi v1, v2, 15");
  VCMP_U32(19, v1, 0xfffffff0, 0x0000000e, 0xf0f0f0ff, 0xfffffff0, 0x0000000e,
           0xf0f0f0ff, 0xfffffff0, 0x0000000e, 0xf0f0f0ff, 0xfffffff0,
           0x0000000e, 0xf0f0f0ff);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   asm volatile("vxor.vi v1, v2, 15");
//   VCMP_U64(20, v1, 0xfffffffffffffff0, 0x000000000000000e, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0x000000000000000e, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0x000000000000000e, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0x000000000000000e, 0xf0f0f0f0f0f0f0ff);
 }

void TEST_CASE6() {
  VSET(12, e8, m1);
  VLOAD_8(v2, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01, 0xf0, 0xff, 0x01,
          0xf0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_8(v1, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef, 0xef,
          0xef);
  asm volatile("vxor.vi v1, v2, 15, v0.t");
  VCMP_U8(21, v1, 0xf0, 0xef, 0xff, 0xf0, 0xef, 0xff, 0xf0, 0xef, 0xff, 0xf0,
          0xef, 0xff);

  VSET(12, e16, m1);
  VLOAD_16(v2, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001, 0xf0f0, 0xffff, 0x0001,
           0xf0f0, 0xffff, 0x0001, 0xf0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_16(v1, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef, 0xbeef,
           0xbeef, 0xbeef, 0xbeef, 0xbeef);
  asm volatile("vxor.vi v1, v2, 15, v0.t");
  VCMP_U16(22, v1, 0xfff0, 0xbeef, 0xf0ff, 0xfff0, 0xbeef, 0xf0ff, 0xfff0,
           0xbeef, 0xf0ff, 0xfff0, 0xbeef, 0xf0ff);

  VSET(12, e32, m1);
  VLOAD_32(v2, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
           0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
           0x00000001, 0xf0f0f0f0);
  VLOAD_8(v0, 0x6D, 0x0B);
  VLOAD_32(v1, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef, 0xdeadbeef,
           0xdeadbeef, 0xdeadbeef);
  asm volatile("vxor.vi v1, v2, 15, v0.t");
  VCMP_U32(23, v1, 0xfffffff0, 0xdeadbeef, 0xf0f0f0ff, 0xfffffff0, 0xdeadbeef,
           0xf0f0f0ff, 0xfffffff0, 0xdeadbeef, 0xf0f0f0ff, 0xfffffff0,
           0xdeadbeef, 0xf0f0f0ff);

//   VSET(12, e64, m1);
//   VLOAD_64(v2, 0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0,
//            0xffffffffffffffff, 0x0000000000000001, 0xf0f0f0f0f0f0f0f0);
//   VLOAD_8(v0, 0x6D, 0x0B);
//   VLOAD_64(v1, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef,
//            0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef);
//   asm volatile("vxor.vi v1, v2, 15, v0.t");
//   VCMP_U64(40, v1, 0xfffffffffffffff0, 0xdeadbeefdeadbeef, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0xdeadbeefdeadbeef, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0xdeadbeefdeadbeef, 0xf0f0f0f0f0f0f0ff,
//            0xfffffffffffffff0, 0xdeadbeefdeadbeef, 0xf0f0f0f0f0f0f0ff);
}

static volatile uint32_t VM2_I32[32] = {
           0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff, 0x00000002,
           0x00000000, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff,
           0x00000002, 0x00000000, 0x0000ffff, 0x00000002, 0x00000000, 0x0000ffff, 0x00000002, 0x00000000
};

void TEST_CASE7(void) {
  VSET(24, e32, m2);
  VLOAD_32(v2,  0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001,
                0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff,
                0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0, 0xffffffff, 0x00000001, 0xf0f0f0f0);
  VLOAD_32(v4,  0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003,
                0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000,
                0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0, 0xffff0000, 0x00000003, 0xf0f0f0f0);
  asm volatile("vxor.vv v6, v2, v4");
  LVCMP_U32(25, v6, 24, VM2_I32);
};

int main(void) {
  INIT_CHECK();
  enable_vec();

  TEST_CASE1();
  TEST_CASE2();
  TEST_CASE3();
  TEST_CASE4();
  TEST_CASE5();
  TEST_CASE6();
  TEST_CASE7();

  EXIT_CHECK();
}
